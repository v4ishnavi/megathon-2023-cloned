{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 09:55:37.748745: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-29 09:55:37.818898: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-29 09:55:38.222044: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-29 09:55:38.222085: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-29 09:55:38.225050: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-29 09:55:38.458431: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-29 09:55:38.461370: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-29 09:55:40.066701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, GlobalAveragePooling2D, Dense\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'./RiceLeafs/train'\n",
    "test_dir = r'./RiceLeafs/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Unhealthy', 'Healthy']\n",
    "indices = range(len(classes))\n",
    "normal_mapping = dict(zip(classes, indices))\n",
    "reverse_mapping = dict(zip(indices, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "class_index = 0\n",
    "\n",
    "for file in os.listdir(train_dir):\n",
    "    path = os.path.join(train_dir, file)\n",
    "    for im in os.listdir(path):\n",
    "        image = load_img(os.path.join(path, im), grayscale=False, color_mode='rgb', target_size=(80,80))\n",
    "        image = img_to_array(image)\n",
    "        image /= 255\n",
    "        training_data += [[image,class_index]]\n",
    "    class_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "class_index = 0\n",
    "\n",
    "for file in os.listdir(test_dir):\n",
    "    path = os.path.join(test_dir, file)\n",
    "    for im in os.listdir(path):\n",
    "        image = load_img(os.path.join(path, im), grayscale=False, color_mode='rgb', target_size=(80,80))\n",
    "        image = img_to_array(image)\n",
    "        image /= 255\n",
    "        test_data += [[image,class_index]]\n",
    "    class_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_labels = zip(*training_data)\n",
    "testing_images, testing_labels = zip(*test_data)\n",
    "\n",
    "training_labels = np.array(to_categorical(training_labels))\n",
    "training_images = np.array(training_images)\n",
    "testing_images = np.array(testing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1287, 2)\n",
      "(322, 2)\n",
      "(1287, 80, 80, 3)\n",
      "(322, 80, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(training_images,training_labels,test_size=0.2,random_state=44)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    # brightness_range=[0.8, 1.2],  # Slight color jitter\n",
    "    # channel_shift_range=20  # Slight color jitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 80, 80, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 40, 40, 64)           9472      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 40, 40, 64)           256       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 40, 40, 64)           0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 40, 40, 64)           36928     ['re_lu_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 40, 40, 64)           256       ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (None, 40, 40, 64)           0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 40, 40, 64)           36928     ['re_lu_11[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 40, 40, 64)           256       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 40, 40, 64)           0         ['re_lu_10[0][0]',            \n",
      "                                                                     'batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (None, 40, 40, 64)           0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 40, 40, 64)           36928     ['re_lu_12[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 40, 40, 64)           256       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (None, 40, 40, 64)           0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 40, 40, 64)           36928     ['re_lu_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 40, 40, 64)           256       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 40, 40, 64)           0         ['re_lu_12[0][0]',            \n",
      "                                                                     'batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (None, 40, 40, 64)           0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['re_lu_14[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 2)                    130       ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 158594 (619.51 KB)\n",
      "Trainable params: 157954 (617.01 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([shortcut, x])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "input = Input(shape=(80, 80, 3))\n",
    "x = Conv2D(64, (7, 7), padding=\"same\", strides=2)(input)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(2, activation=\"softmax\")(x)  # Assuming 2 classes for classification\n",
    "\n",
    "model = keras.Model(inputs=input, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "41/41 [==============================] - 19s 386ms/step - loss: 0.2583 - accuracy: 0.9044 - val_loss: 0.5280 - val_accuracy: 0.7547\n",
      "Epoch 2/5\n",
      "41/41 [==============================] - 15s 368ms/step - loss: 0.2202 - accuracy: 0.9138 - val_loss: 2.7713 - val_accuracy: 0.2484\n",
      "Epoch 3/5\n",
      "41/41 [==============================] - 15s 356ms/step - loss: 0.2067 - accuracy: 0.9254 - val_loss: 1.5339 - val_accuracy: 0.2484\n",
      "Epoch 4/5\n",
      "41/41 [==============================] - 15s 356ms/step - loss: 0.2000 - accuracy: 0.9316 - val_loss: 2.6570 - val_accuracy: 0.2484\n",
      "Epoch 5/5\n",
      "41/41 [==============================] - 15s 354ms/step - loss: 0.2025 - accuracy: 0.9293 - val_loss: 2.4650 - val_accuracy: 0.2484\n"
     ]
    }
   ],
   "source": [
    "his=model.fit(datagen.flow(x_train,y_train,batch_size=32),validation_data=(x_test,y_test),epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshvardhanpandey/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"resnet90.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
